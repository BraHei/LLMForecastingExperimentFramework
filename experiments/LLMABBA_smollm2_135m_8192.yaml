checkpoint_name: "smollm2-135m"
tokenizer_name: "LLM-ABBA"
max_new_tokens: 250
num_series: 10
max_kernels: 5
sequence_length: 8192
prompt_length_factor: 0.8
output_jsonl: "model_responses.jsonl"
tokenizer_params:
  tol: 0.1
  alpha: 0.1
data_analyzers: [MAE, MSE, RMSE]