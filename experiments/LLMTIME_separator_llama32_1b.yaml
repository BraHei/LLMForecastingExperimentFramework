model_name: llama3.2-1b

model_parameters:
  temperature: 0.5
  do_sample: true
  num_return_sequences: 5

dataset_name: "darts"
dataset_params:
  dataset_names: ["AirPassengers", "MonthlyMilk", "IceCreamHeater", "Wooly", "AusBeer"]

preprocessor_name: "LLMTime"
preprocessor_params_grid:
  alpha: [0.9]
  beta: [0.0]
  base: [10]
  prec: [3]
  time_sep:
    - '.'
    - '_'
    - '-'
    - '|'
    - '/'
    - ':'
    - '#'
    - '$'
    - '%'
    - '^'
    - '&'
    - '>'
    - '->'
    - ')('
    - ']['
    - '}{'
    - ' '
    - '\n'
    - '\t'

input_data_factor: 0.8
output_dir: 'results/LLMTIME_seperator_llama32_1b'
output_jsonl: "model_responses.jsonl"
data_analyzers: [MAE, MSE, MASE]
