model_name: "llama3"
model_parameters:
  max_new_tokens: 500
  temperature: 1.0
  top_p: 0.9
  use_auth_token: True
  access_token: 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
tokenizer_name: "LLMTime"
dataset_name: "darts"
dataset_params:
  dataset_names: ["AirPassengers", "AusBeer", "HeartRate", "MonthlyMilk", "Sunspots", "Temperature", "Wooly"]
prompt_length_factor: 0.95
output_jsonl: "model_responses.jsonl"
tokenizer_params: {}
data_analyzers: [MAE, MSE, RMSE]