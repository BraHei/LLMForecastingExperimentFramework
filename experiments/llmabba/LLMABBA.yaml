model_name_grid:
  - distilgpt2-88m
  - smollm2-135m
  - smollm2-360m
  - llama3.2-1b
  - smollm2-1.7b
  - llama3.1-8b
  - llama3.2-3b

model_parameters_grid:
  max_new_tokens: [100]
  temperature: [0.25, 0.5, 0.75]
  top_p: [0.9]
  do_sample: [true]
  num_return_sequences: [10]
dataset_name: "darts"
dataset_params:
  dataset_names: ["AirPassengers", "MonthlyMilk", "IceCreamHeater", "Wooly", "AusBeer"]
preprocessor_name: "LLM-ABBA"
preprocessor_params_grid:
  separator: [',']
  symbol_set: ["Numbers"]
  # symbol_set: ["Numbers", "AlphabetAa", "Specials"]
  tol: [0.001]
  alpha: [0.001]
  init: ['agg']
input_data_factor: 0.8
output_dir: 'results/LLMABBA_grid'
output_jsonl: "model_responses.jsonl"
data_analyzers: [MAE, MSE, MASE]
