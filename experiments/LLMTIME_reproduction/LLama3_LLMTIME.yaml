model_name: "llama3"
model_parameters:
  max_new_tokens: 150
  temperature: 1.0
  top_p: 0.9
  do_sample: true
dataset_name: "darts"
dataset_params:
  dataset_names: ["AirPassengers", "MonthlyMilk", "HeartRate", "GasRateCO2", "Wooly"]
tokenizer_name: "LLMTime"
tokenizer_params:
  alpha: 0.99
  beta: 0.3
input_data_factor: 0.8
output_jsonl: "model_responses.jsonl"
data_analyzers: [MAE, MSE, RMSE]
